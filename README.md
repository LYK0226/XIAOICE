# XIAOICE æ™ºèƒ½èŠå¤©åŠ©æ‰‹ ğŸ¤–

XIAOICE is an intelligent chat assistant with multimodal support (text, images, videos) and real-time pose detection capabilities.

### âš ï¸ **é‡è¦**ï¼šå»ºç«‹ä¸€å€‹åç‚ºã€Œ.credentialsã€çš„æ–°è³‡æ–™å¤¾ï¼Œä¸¦å°‡ GCP æ†‘è­‰æ”¾å…¥å…¶ä¸­ã€‚ï¼

## Features

- ğŸ¤– **Multi-agent AI System**: Powered by Google ADK with specialized agents for text and media
- ğŸ’¬ **Real-time Chat**: WebSocket-based streaming responses
- ğŸ–¼ï¸ **Multimodal Support**: Analyze images and videos (up to 500MB)
- ğŸ§ **Pose Detection**: Real-time human pose detection and action recognition via webcam
- ğŸ” **Secure Authentication**: JWT-based authentication with encrypted API key storage
- ğŸŒ **Multi-language**: Support for Chinese (Traditional), English, and Japanese
- ğŸ¨ **Customizable**: User preferences for themes, language, and AI models
 
### Setting up your .env file (step-by-step) âœ…

```bash
# Copy .env.example to .env
cp .env.example .env

# Generate secure secret values (choose one of the generators below):
# Secure Flask / JWT secret (recommended for both):
python -c "import secrets; print(secrets.token_urlsafe(48))"

# `ENCRYPTION_KEY` 
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```


### å®‰è£ä¾è³´ä¸¦å•Ÿå‹•æ‡‰ç”¨

```bash
# å»ºç«‹ä¸¦å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
python -m venv .venv && source .venv/bin/activate
# windows
python -m venv .venv; .\.venv\Scripts\Activate

# å®‰è£ Python ä¾è³´
pip install -r requirements.txt

# åˆå§‹åŒ–é·ç§»è³‡æ–™åº«
flask db init
flask db migrate 
flask db upgrade

# å•Ÿå‹•æ‡‰ç”¨
python run.py
flask --debug run --host=0.0.0.0
```
### è³¦äºˆç®¡ç†å“¡æ¬Šé™

```bash
# å»ºç«‹ç®¡ç†å“¡å¸³è™Ÿ
python create_admin.py

username = 'admin@gmail.com'
password = 'admin'
```

### æ¸¬è©¦

```bash
# é‹è¡Œæ‰€æœ‰æ¸¬è©¦
pytest

# é‹è¡Œå–®ä¸€æ¸¬è©¦æ–‡ä»¶
pytest test/test_rag.py -v

# é‹è¡Œå–®ä¸€æ¸¬è©¦
pytest test/test_rag.py::TestRagEndpoints::test_list_documents_requires_admin -v

# API é€£æ¥æ¸¬è©¦
python test_api.py
```

### Docker ä¼ºæœå™¨

```bash
# å•Ÿå‹• Docker ä¼ºæœå™¨
cd .devcontainer && docker-compose up -d

# åœæ­¢ Docker ä¼ºæœå™¨
cd .devcontainer && docker-compose down

# åˆ—å‡º Docker ä¼ºæœå™¨
cd .devcontainer && docker ps
```

## Pose Detection Feature

The pose detection feature enables real-time human pose tracking and action recognition through your webcam.

### Quick Start

1. **Open XIAOICE**: Navigate to the main chat interface
2. **Click Pose Detection Button**: Activate the pose detection mode
3. **Allow Camera Access**: Grant permission when prompted
4. **Start Moving**: The system will detect your pose and recognize your actions in real-time

### Supported Actions
- **Standing**: Upright posture with arms at sides
- **Sitting**: Seated position with bent hips and knees
- **Walking**: Alternating leg movements
- **Raising Hands**: One or both hands above shoulder level
- **Squatting**: Bent knees with lowered hips

ğŸ“– **For detailed instructions, troubleshooting, and tips, see the [Pose Detection User Guide](document/POSE_DETECTION_USER_GUIDE.md)**

### Performance Tips
- Use `POSE_MODEL_COMPLEXITY=0` for faster processing on lower-end hardware
- Increase confidence thresholds for more accurate but stricter detection
- Reduce `POSE_MAX_CONCURRENT_SESSIONS` if experiencing high CPU usage

### Browser Compatibility
- Ensure your browser has webcam permissions enabled
- For best performance, use Chrome or Edge (Chromium-based browsers)
- Safari users may need to enable camera access in System Preferences

### Privacy & Security
- âœ… Real-time processing only - no video recording
- âœ… No data storage - frames are immediately discarded
- âœ… Secure WebSocket connections
- âœ… No third-party data sharing

## Key Dependencies

### Backend
- **Flask 3.1.2**: Web framework
- **Flask-SocketIO 5.4.1**: Real-time WebSocket communication
- **Google ADK 1.18.0**: Multi-agent AI system
- **Google GenAI 1.52.0**: AI model integration
- **Google Cloud Storage 3.5.0**: File storage
- **SQLAlchemy**: Database ORM
- **Cryptography 46.0.3**: API key encryption
- **Pillow 12.0.0**: Image processing

### Frontend
- **MediaPipe Pose (Browser)**: Real-time 3D pose detection
- **WebRTC**: Webcam access
- **Canvas API**: Pose visualization

### Testing
- **pytest â‰¥9.0.1**: Unit testing framework
- **Hypothesis 6.148.7**: Property-based testing

##  å°ˆæ¡ˆçµæ§‹

```
XIAOICE/
â”œâ”€â”€ .devcontainer/                   # Docker é–‹ç™¼ç’°å¢ƒé…ç½®
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ pgadmin_servers.xml
â”œâ”€â”€ .vscode/                          # VS Code workspace settings
â”œâ”€â”€ app/                              # Flask æ‡‰ç”¨ç¨‹å¼èˆ‡ AI agent
â”‚   â”œâ”€â”€ __init__.py                   # create_app()ã€Blueprint èˆ‡ SocketIO åˆå§‹åŒ–
â”‚   â”œâ”€â”€ adk.py                        # ADK é€£ç·š / session helpers
â”‚   â”œâ”€â”€ AGENTS.md                     # agent è¨­è¨ˆèˆ‡å”èª¿èªªæ˜
â”‚   â”œâ”€â”€ auth.py                       # JWT é©—è­‰ã€ç™»å…¥/è¨»å†Šé‚è¼¯
â”‚   â”œâ”€â”€ child_assessment.py           # å…’ç«¥è©•ä¼°æµç¨‹èˆ‡åˆ†æ•¸è¨ˆç®—
â”‚   â”œâ”€â”€ config.py                     # ç’°å¢ƒèˆ‡è¨­å®šå¸¸æ•¸
â”‚   â”œâ”€â”€ gcp_bucket.py                 # GCS ä¸Šå‚³/ä¸‹è¼‰/åˆªé™¤ API å°è£
â”‚   â”œâ”€â”€ models.py                     # ORMï¼šUser, Conversation, Message, FileUpload
â”‚   â”œâ”€â”€ report_generator.py           # ç”¢ç”Ÿå½±ç‰‡ï¼è©•ä¼°å ±è¡¨ (PDF/JSON)
â”‚   â”œâ”€â”€ routes.py                     # SSE `/chat/stream`ã€ä¸Šå‚³ã€æœƒè©±ç®¡ç†ç­‰ HTTP endpoints
â”‚   â”œâ”€â”€ socket_events.py              # Socket.IO connect/streaming handlers (JWT on connect)
â”‚   â”œâ”€â”€ video_access_routes.py        # å—æ§å½±ç‰‡å­˜å– URL / æ¬Šé™æª¢æŸ¥
â”‚   â”œâ”€â”€ video_cleanup.py              # èƒŒæ™¯æ¸…ç†å·¥ä½œ (éæœŸæª”æ¡ˆã€æš«å­˜)
â”‚   â”œâ”€â”€ video_processor.py            # å½±ç‰‡ä¸Šå‚³å¾Œçš„åˆ†æ pipeline / å­˜å„²æµç¨‹
â”‚   â”œâ”€â”€ agent/                        # Multi-agent AI system (ADK coordinator + specialists)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ AGENTS.md
â”‚   â”‚   â”œâ”€â”€ chat_agent.py             # å”èª¿å™¨ï¼šç®¡ç†æœƒè©±ä¸Šä¸‹æ–‡ã€streamingã€æ¨¡å‹é¸æ“‡
â”‚   â”‚   â”œâ”€â”€ knowledge_base.py        # RAG æ”¯æ´ã€æ–‡ä»¶è™•ç†èˆ‡æª¢ç´¢é‚è¼¯
â”‚   â”‚   â”œâ”€â”€ prompts.py                # å…§å»º prompt èˆ‡ system instructions
â”‚   â”‚   â”œâ”€â”€ video_analysis_agent.py   # å½±ç‰‡/å¤šåª’é«”å°ˆç”¨ agent
â”‚   â”‚   â””â”€â”€ instructions/             # agent prompts èˆ‡ç‰‡æ®µ
â”‚   â”œâ”€â”€ pose_detection/               # å§¿å‹¢æª¢æ¸¬ï¼šå‰ç«¯ JS + å¾Œç«¯è©•ä¼°
â”‚   â”‚   â”œâ”€â”€ pose_assessment.py        # å¾Œç«¯è©•åˆ†/è¦å‰‡å¼•æ“ï¼ˆæŠŠå§¿å‹¢è³‡æ–™è½‰æˆè©•ä¼°åˆ†æ•¸ï¼‰
â”‚   â”‚   â”œâ”€â”€ action_detector.js        # å‹•ä½œåˆ†é¡å™¨
â”‚   â”‚   â”œâ”€â”€ movement_analyzers.js    # å„éƒ¨ä½å‹•ä½œåˆ†æé‚è¼¯
â”‚   â”‚   â”œâ”€â”€ movement_descriptor.js   # è‡ªç„¶èªè¨€æè¿°ç”Ÿæˆå™¨
â”‚   â”‚   â”œâ”€â”€ movement_detector.js     # åµæ¸¬å‹•ä½œäº‹ä»¶
â”‚   â”‚   â”œâ”€â”€ multi_person_detector.js # å¤šäººè¿½è¹¤/é¸å–
â”‚   â”‚   â”œâ”€â”€ multi_person_selector.js # äººç‰©é¸æ“‡ UI é‚è¼¯
â”‚   â”‚   â”œâ”€â”€ pose_detector_3d.js      # MediaPipe client-side 3D åµæ¸¬
â”‚   â”‚   â”œâ”€â”€ pose_error_handler.js    # åµæ¸¬éŒ¯èª¤è™•ç†
â”‚   â”‚   â””â”€â”€ pose_renderer.js         # Canvas æ¸²æŸ“èˆ‡ overlay
â”‚   â”œâ”€â”€ rag/                          # RAG / embeddings å·¥å…·
â”‚   â”‚   â”œâ”€â”€ chunker.py               # æ–‡ä»¶åˆ†æ®µ
â”‚   â”‚   â”œâ”€â”€ embeddings.py            # å‘é‡åŒ–/embedding wrapper
â”‚   â”‚   â”œâ”€â”€ processor.py             # æ–‡æœ¬è™•ç† pipeline
â”‚   â”‚   â””â”€â”€ retriever.py             # ç›¸ä¼¼åº¦æª¢ç´¢
â”‚   â”œâ”€â”€ static/                       # éœæ…‹è³‡æº (UIã€JSã€CSS)
â”‚   â”‚   â”œâ”€â”€ css/                      # è¦–è¦ºæ¨£å¼
â”‚   â”‚   â”œâ”€â”€ data/                     # emojis.jsonã€i18n è³‡æº
â”‚   â”‚   â”œâ”€â”€ i18n/                     # ç¿»è­¯æª”
â”‚   â”‚   â”œâ”€â”€ js/                       # `chatbox.js`ï¼ˆä¸» UIï¼‰ï¼Œ`pose_detection.js`ï¼ˆå‰ç«¯æª¢æ¸¬ UIï¼‰
â”‚   â”‚   â””â”€â”€ upload/                   # å‰ç«¯ä¸Šå‚³æš«å­˜
â”‚   â””â”€â”€ templates/                    # Jinja æ¨¡æ¿ (chat, auth, settings, assessments)
â”œâ”€â”€ videos_quesyions/                 # æ•™å­¸èˆ‡è©•ä¼°ç”¨å½±ç‰‡ç›®éŒ„
â”œâ”€â”€ docs/                             # ä½¿ç”¨æ‰‹å†Šã€æ¶æ§‹èˆ‡éƒ¨ç½²èªªæ˜
â”œâ”€â”€ migrations/                       # Alembic migration æª”æ¡ˆ
â”‚   â””â”€â”€ versions/                      # schema ç‰ˆæœ¬æ­·å²
â”œâ”€â”€ test/                             # pytest æ¸¬è©¦ (å–®å…ƒèˆ‡æ•´åˆæ¸¬è©¦)
â”œâ”€â”€ create_admin.py                   # å»ºç«‹ç®¡ç†å“¡ä½¿ç”¨çš„ç°¡æ˜“è…³æœ¬
â”œâ”€â”€ run.py                            # æœ¬åœ°é–‹ç™¼ä¼ºæœå™¨å•Ÿå‹•æŒ‡ä»¤
â”œâ”€â”€ test_vertex_account.py            # ç¯„ä¾‹ / é©—è­‰å¸³è™Ÿæ¸¬è©¦å·¥å…·
â”œâ”€â”€ requirements.txt                  # Python ç›¸ä¾å¥—ä»¶
â”œâ”€â”€ package-lock.json                 # Node å‰ç«¯ä¾è³´é–æª”
â”œâ”€â”€ README.md                         # æœ¬æª”æ¡ˆ
â”œâ”€â”€ .env.example / .env               # ç’°å¢ƒè®Šæ•¸ç¯„æœ¬èˆ‡ (æœ¬åœ°) .env
â””â”€â”€ view_database.py                  # DB æŸ¥è©¢ / æª¢è¦–å°å·¥å…·
```

# Install opencode and the plugin
```bash
npm install -g @google/gemini-cli
npm i -g opencode-ai
npx oh-my-opencode install --no-tui --claude=no --openai=no --gemini=yes --copilot=yes
```
